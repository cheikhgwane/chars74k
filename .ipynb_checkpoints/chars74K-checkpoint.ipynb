{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample directory : 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 400x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of one random image : (128, 128)\n",
      " Example image : \n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from random import randint\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "# path to directory\n",
    "base_dir = \"C:\\\\Users\\\\Cheikh\\\\Desktop\\\\projetChars74k\"\n",
    "\n",
    "fnt_base_dir = os.path.join(base_dir, \"EnglishFnt\")\n",
    "img_base_dir = os.path.join(base_dir, \"EnglishImg\")\n",
    "hnd_base_dir = os.path.join(base_dir, \"EnglishHnd\")\n",
    "\n",
    "# utils functions used to plot random image in dataset\n",
    "\n",
    "\n",
    "def showFolderImageSample(base_folder, img_number=2):\n",
    "    '''\n",
    "    base_folder(String) : directory in which we'll look for sample\n",
    "    img_number : for each folder how many img to show\n",
    "    '''\n",
    "    nrows = ncols = img_number\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(ncols * img_number, nrows * img_number)\n",
    "    dir_names = os.listdir(base_folder)\n",
    "\n",
    "    # get sample directory\n",
    "    sample_dir = []\n",
    "    for i in range(img_number):\n",
    "        sample_dir.append(dir_names[randint(0, 61)])\n",
    "    dir_names = [os.path.join(base_folder, dname) for dname in sample_dir]\n",
    "\n",
    "    print(\"total sample directory : {}\".format(len(dir_names)))\n",
    "    # for each sample directory get img_number random image\n",
    "\n",
    "    img = []\n",
    "    for d in dir_names:\n",
    "        for i in range(img_number):\n",
    "            img.append(os.path.join(d, os.listdir(\n",
    "                d)[randint(0, len(os.listdir(d)) - 1)]))\n",
    "\n",
    "    for i, img_path in enumerate(img):\n",
    "        # Set up subplot; subplot indices start at 1\n",
    "        sp = plt.subplot(nrows, ncols, i + 1)\n",
    "        sp.axis('Off')  # Don't show axes (or gridlines)\n",
    "        img = mpimg.imread(img_path)\n",
    "        plt.imshow(img)\n",
    "\n",
    "    plt.show()\n",
    "    print(\"Size of one random image : {}\".format(img.shape))\n",
    "    print(\" Example image : \\n {}\".format(img[0]))\n",
    "\n",
    "########################################################################\n",
    "\n",
    "\n",
    "def dirTotalFile(base):\n",
    "    fileNumber = 0\n",
    "    if(os.path.isfile(base)):\n",
    "        return 0\n",
    "    _dir = os.listdir(base)\n",
    "    for d in _dir:\n",
    "        _d = os.path.join(base, d)\n",
    "        if(os.path.isdir(_d)):\n",
    "            fileNumber += dirTotalFile(_d)\n",
    "        else:\n",
    "            fileNumber += 1\n",
    "    return fileNumber\n",
    "\n",
    "\n",
    "########################################################################\n",
    "\n",
    "showFolderImageSample(fnt_base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training dataset image....\n",
      "100.00% \n",
      " Time for reading training images : 141.3140993118286\n",
      "Reading test dataset image....\n",
      "100.00% \n",
      " Time for reading test images : 48.6040563583374\n"
     ]
    }
   ],
   "source": [
    "_list = [i for i in range(0, 10)] + [chr(i) for i in range(97, 123)] + [chr(i) for i in range(65, 91)]\n",
    "\n",
    "\n",
    "class Utils:\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.files = {}\n",
    "\n",
    "    def readImage(self, start, size, _type):\n",
    "        print('Reading {} dataset image....'.format(_type))\n",
    "        begin = time.time()\n",
    "        files = self.files\n",
    "        data = []\n",
    "        label = []\n",
    "        j = 0\n",
    "        #\n",
    "        for key in files.keys():\n",
    "            for i in range(start, start+size):\n",
    "                label.append(key)\n",
    "                data.append(plt.imread(files[key][i]))\n",
    "            j = j + 1.613\n",
    "            if(j > 100):\n",
    "                j = 100\n",
    "            sys.stdout.write(\"\\r{0:.2f}%\".format(j))\n",
    "            sys.stdout.flush()\n",
    "        end = time.time()\n",
    "        le = LabelEncoder()\n",
    "        label = le.fit_transform(label)\n",
    "        label = to_categorical(label)\n",
    "\n",
    "        print(\" \\n Time for reading {} images : {}\".format(_type, end-begin))\n",
    "        return np.array(data), label\n",
    "\n",
    "    def loadData(self):\n",
    "\n",
    "        train_images_size = 775\n",
    "        test_size = 241\n",
    "\n",
    "        path = self.path\n",
    "        files = self.files\n",
    "\n",
    "        if(not(os.path.exists(path))):\n",
    "            raise(\"Directory doesn't exist\")\n",
    "\n",
    "        dnames = [os.path.join(path, dname) for dname in os.listdir(path)]\n",
    "\n",
    "        # read all the image\n",
    "        for i, label in enumerate(_list):\n",
    "            if(not(os.path.isdir(dnames[i]))):\n",
    "                continue\n",
    "            files[label] = [os.path.join(dnames[i], f) for f in os.listdir(dnames[i])]\n",
    "        \n",
    "        train, train_label = self.readImage(0, train_images_size, \"training\")\n",
    "        \n",
    "        test, test_label = self.readImage(train_images_size, test_size, \"test\")\n",
    "        \n",
    "        return (train, train_label),(test, test_label)\n",
    "\n",
    "\n",
    "utils = Utils(fnt_base_dir)\n",
    "(train, train_label),(test, test_label) = utils.loadData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 787251200 into shape (48050,128,128,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-40599e4f5b1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# keras font model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 787251200 into shape (48050,128,128,3)"
     ]
    }
   ],
   "source": [
    "# keras font model\n",
    "\n",
    "print(train.shape)\n",
    "train = train.reshape(train.shape[0],128,128,3)\n",
    "\n",
    "train = train.astype('float32') / 255\n",
    "\n",
    "test = test.reshape(test.shape[0],128,128,3)\n",
    "test = test.astype('float32') / 255\n",
    "\n",
    "epochs = 10\n",
    "nodes = 32\n",
    "optimizer = 'rmsprop'\n",
    "\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(32,activation = 'relu', input_shape=(128,128,3)))\n",
    "network.add(layers.Dense(10,activation='softmax'))\n",
    "network.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "network.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['acc'])\n",
    "\n",
    "\n",
    "history = network.fit(train, train_label, batch_size=32,\n",
    "                      epochs=epochs)\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "acc_values = history_dict['acc']\n",
    "plt.rcParams['figure.figsize'] = (16, 8)  # Make the figures a bit bigger\n",
    "fig, (ax1, ax2,) = plt.subplots(1, 2)\n",
    "\n",
    "x = range(1, epochs+1)\n",
    "ax1.plot(x, loss_values, 'bo', label='Training Loss')\n",
    "ax1.set_title('Training loss ')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2.plot(x, acc_values, 'bo', label='Training Accuracy')\n",
    "ax2.set_title('Training accuracy ')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = network.evaluate(test,test_label)\n",
    "print('accuracy on test set : {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = network.predict_classes(test,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Conv2D(16,3,activation='relu',input_shape=(128,128,3)))\n",
    "network.add(layers.MaxPooling2D(2))\n",
    "network.add(layers.Flatten())\n",
    "network.add(layers.Dense(62, activation='softmax'))\n",
    "network.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
